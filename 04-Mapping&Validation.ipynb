{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021 David Bazzett  \n",
    "The purpose of this code is to  \n",
    "1) BEGIN LOOP: Generate forecast tables for NWM reanalysis timeseries data (converted from HDF5 to NetCDF format) using the NFIE hydrotables  \n",
    "2) Find the maximum flows in each COMID during the analysis period and generate a single forecast table of maximum inundation data  \n",
    "3) Generate an inundation map from the MaxFlow forecast  \n",
    "4) Validate the inundation data against the validation data (high water marks)  \n",
    "5) Update the Manning's N in the hydrotables based on the model accuracy OR EXIT LOOP  \n",
    "Repeat steps 1-5 until the Manning's N is accurate and an exit condition is met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import dbfread as dbf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpdateManning():\n",
    "    # Load data sets\n",
    "    nhd = pd.DataFrame(iter(dbf.read(nhd_file)))\n",
    "    hydrotable = pd.read_csv(hydrotable_file)\n",
    "\n",
    "    # Read the unique COMIDs from your hydrotable, put them in a new dataframe\n",
    "    # Add the NDH data for these COMIDS (NHD file contains data for all 2.7M COMIDS)\n",
    "    df1 = pd.DataFrame(hydrotable[\"CatchId\"].unique(), columns=[\"ComID\"])\n",
    "    df1['Order'] = \"\"\n",
    "    df1 = df1.merge(nhd,on='ComID')\n",
    "\n",
    "    # Create a small dataframe with just the COMID and stream order\n",
    "    # Format column names and merge to hydrotable\n",
    "    df2 = df1[['StreamOrde','ComID']].copy()\n",
    "    df2 = df2.rename(columns={'ComID':'CatchId'})\n",
    "    hydrotable = hydrotable.merge(df2,on='CatchId')\n",
    "\n",
    "    # This is a csv of Manning's N based on stream order. The initial data is from the CAHABA Manning's data\n",
    "    # Merge this roughness data into the hydrotable\n",
    "    rough = pd.read_csv(rough_file)\n",
    "    hydrotable = hydrotable.merge(rough,on='StreamOrde')\n",
    "\n",
    "    # Calculate flow based on the new Manning's N\n",
    "    hydrotable['Discharge (m3s-1)'] = hydrotable['WetArea (m2)'] * pow(hydrotable['HydraulicRadius (m)'],2.0/3) * \\\n",
    "        pow(hydrotable['SLOPE'],0.5) / hydrotable['rough']\n",
    "    \n",
    "    # TODO: Do we overwrite the existing hydrotable or create a new one?\n",
    "    # Write new table to file (comment out for testing)\n",
    "    # hydrotable.to_csv(\"C:/Users/David/G-Rutgers/020301/hydrogeo-fulltable-020301-updated.csv\")\n",
    "    print('UpdateManning complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code should ideally create a blank dataframe and append all flow data to it\n",
    "# Not sure how to do this, so I read the first file, then append all data to it\n",
    "# This results in 1 duplicate timestep in the dataset, which doesn't make a difference\n",
    "\n",
    "def MaxFlow():\n",
    "    file_path = forecast_path + 'inun*csv'\n",
    "    \n",
    "    # Read the first file in the path to start the table, then break\n",
    "    # This method seems awkward but it works for now\n",
    "    for path in glob.iglob(file_path):\n",
    "        date = path[-19:-8] # strip date and time from filename, use for column names\n",
    "        df1 = pd.read_csv(path)\n",
    "        df1 = df1.rename(columns={\"H\": date + \"_H\", \"Q\": date + \"_Q\"})\n",
    "        break\n",
    "\n",
    "    # Once you have the initial table set up, add the remaining data.\n",
    "    # You will have duplicates of the first row because of this method, but it doesn't matter when looking for maximums\n",
    "    for path in glob.iglob(file_path):\n",
    "        date = path[-19:-8] # strip date and time from filename, use for column names\n",
    "        df2 = pd.read_csv(path)\n",
    "        df2 = df2.rename(columns={\"H\": date + \"_H\", \"Q\": date + \"_Q\"})\n",
    "        df1 = df1.merge(df2, on='COMID')\n",
    "\n",
    "    df1 = df1.set_index(['COMID'])\n",
    "\n",
    "    # Create a dataframe of all flow values Q, find the maximum flows in the timeseries\n",
    "    flow = df1.filter(like='Q', axis=1)\n",
    "    flow['fmax'] = ''\n",
    "    flow.fmax = flow.max(axis=1)\n",
    "\n",
    "    # Create a dataframe of all height values H, find the maximum heights in the timeseries\n",
    "    ht = df1.filter(like='H', axis=1)\n",
    "    ht['hmax'] = ''\n",
    "    ht.hmax = ht.max(axis=1)\n",
    "\n",
    "    # Generate a dataframe of maximum flow and height values for each COMID in the time series\n",
    "    # This will be used to generate the inundation map showing max flooding in each COMID during the event\n",
    "    # This is not to be confused with instantaneous or \"snapshot\" flooding\n",
    "    # Different COMIDs peak at different times - we want to show all maximums regardless of time\n",
    "    maxtbl = pd.DataFrame(flow.fmax)\n",
    "    maxtbl = maxtbl.merge(ht.hmax, left_index=True, right_index=True)\n",
    "    maxtbl = maxtbl.rename(columns={\"fmax\": \"Q\", \"hmax\": \"H\"})\n",
    "\n",
    "    maxtbl.to_csv(forecast_path + 'maxflow.csv')\n",
    "    # flow.to_csv('Irene_flow.csv')\n",
    "    print('MaxFlow complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES:  \n",
    "1) Forecast tables - Roger, the NFIE forecast table script runs in python 2.7. Can we call python 2.7 from within python3? I have a bash script in Amarel to run forecast-table for every forecast in a folder.  \n",
    "\n",
    "2) InunMap - Roger, this is called as a bash script in Amarel. Can we call a bash script from within python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-9438bbb040eb>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  flow['fmax'] = ''\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "<ipython-input-9-9438bbb040eb>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ht['hmax'] = ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxFlow complete!\n"
     ]
    }
   ],
   "source": [
    "# Variables for UpdateManning\n",
    "hydrotable_file = \"C:/Users/David/G-Rutgers/020301/hydrogeo-fulltable-020301.csv\"\n",
    "nhd_file = 'C:/Users/David/G-Rutgers/NHDPlusAttributes/PlusFlowlineVAA.dbf'\n",
    "rough_file = \"./roughness.csv\"\n",
    "\n",
    "# Variables for MaxFlow\n",
    "# forecast_path = './default/' # Path to forecast files (csv)\n",
    "forecast_path = './manning/' # Path to forecast files (csv)\n",
    "\n",
    "# UpdateManning()\n",
    "\n",
    "## TODO: create function for forecast table? See note above\n",
    "\n",
    "MaxFlow()\n",
    "\n",
    "## TODO: create function to call InunMap? See note above\n",
    "\n",
    "## TODO: examine InunMap tif. Compare to Irene shapefile.\n",
    "## If flood depth is over / under estimated, adjust Manning's roughness based on stream order.\n",
    "## Create new table of Manning's roughness vs stream order\n",
    "## Loop until error in estimated / predidicted error is small, then exit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
